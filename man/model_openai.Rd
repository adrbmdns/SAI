% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/models.R
\name{model_openai}
\alias{model_openai}
\title{Set an OpenAI model}
\usage{
model_openai(
  model = "gpt-4o-mini",
  api = NULL,
  format = "none",
  max_tokens = 100,
  temperature = 0,
  top_p = 0.1,
  n = 1,
  stop = NULL,
  presence_penalty = 0.2,
  frequency_penalty = 1
)
}
\arguments{
\item{api}{The API key to use.}

\item{format}{The format}

\item{max_tokens}{The maximum number of tokens to generate. This limits the length of the response.
Tokens refers to a unit of text the model reads and can vary from one character to several words,
varying based on the model. As a rule of thumb 1 token is approximately 4 characters or 0.75 words
for English text.}

\item{temperature}{The temperature of the model where higher temperature means higher creativity.}

\item{top_p}{The nucleus sampling or penalty. It limits the cumulative probability of the most likely tokens.
Higher values allow more tokens and diverse responses, and while lower values are more focused and constrained answers.}

\item{n}{The number of completions/responses to generate.}

\item{stop}{A list of stop sequences to use.}

\item{presence_penalty}{Avoidance of specific topics in response provided in the user messages.
A lower value make the model less concerned about preventing these topics.}

\item{frequency_penalty}{The frequency penalty to use. It discourages the model from repeating the same text.
A lower value results in the model more likely to repeat information.}
}
\description{
Set an OpenAI model
}
\seealso{
Other large-lanugage-models: 
\code{\link{model_mistral}()},
\code{\link{model_ollama}()},
\code{\link{model_vendor}()}
}
\concept{large-lanugage-models}
